{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11231,
     "status": "ok",
     "timestamp": 1670900099167,
     "user": {
      "displayName": "Xiang Li",
      "userId": "03593171086651940008"
     },
     "user_tz": 300
    },
    "id": "pcylTMbz1Dh9"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from models.skip import skip\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.util import random_noise\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from utils.common_utils import get_image, crop_image, pil_to_np, np_to_torch, torch_to_np, get_image_grid, get_noise, plot_image_grid\n",
    "from utils.sr_utils import tv_loss\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "torch.manual_seed(0);\n",
    "np.random.seed(0)\n",
    "save_every = 500\n",
    "num_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_noise(shape, p, sigma):\n",
    "    output = sigma * torch.randn(shape).type(dtype)\n",
    "    output[torch.rand(*output.shape) > p] = 0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path  = 'data/gaussian/xray.jpeg'\n",
    "imsize = 256 # Size of image\n",
    "dim_div_by = 64\n",
    "\n",
    "img_pil, _ = get_image(img_path, imsize)\n",
    "clean_img_np = pil_to_np(crop_image(img_pil, dim_div_by))\n",
    "clean_img_torch = np_to_torch(clean_img_np).type(dtype)\n",
    "\n",
    "signal_size = clean_img_np.size\n",
    "\n",
    "num_measurements = 8000\n",
    "p = 0.1\n",
    "noise_level = 1.0\n",
    "\n",
    "A = np.sqrt(1 / num_measurements) * torch.randn(num_measurements, signal_size).type(dtype)\n",
    "clean_measurement_torch = clean_img_torch.reshape(1, -1) @ A.T\n",
    "noise_torch = sparse_noise(clean_measurement_torch.shape, p=p, sigma=noise_level)\n",
    "noisy_measurement_torch = clean_measurement_torch + noise_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clean_img_np.transpose((1, 2, 0)), cmap='gray')\n",
    "# plt.axis('off')\n",
    "plt.xticks([], minor=True)\n",
    "plt.yticks([], minor=True)\n",
    "plt.savefig('gs_example.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_image_grid([clean_img_np], 3);\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(grid.transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.savefig('gs_example.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for images and psnr\n",
    "image_dict = {}\n",
    "psnr_dict = {}\n",
    "iteration_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 64\n",
    "\n",
    "net = skip(\n",
    "    input_depth,\n",
    "    num_output_channels=1,\n",
    "    num_channels_down = [8, 16, 32, 64, 128], \n",
    "    num_channels_up   = [8, 16, 32, 64, 128],\n",
    "    num_channels_skip = [0, 0, 0, 4, 4],\n",
    "    upsample_mode='bilinear',\n",
    "    need_sigmoid=True,\n",
    ").type(dtype)\n",
    "\n",
    "net_input = torch.randn(1, input_depth, imsize, imsize).type(dtype)\n",
    "criterion = torch.nn.MSELoss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(net_input)\n",
    "    loss = criterion(torch.matmul(out.reshape(1, -1), A.T), clean_measurement_torch)\n",
    "    loss.backward()\n",
    "#     torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.02)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = torch_to_np(out)\n",
    "        plt.imshow(out_np.transpose((1, 2, 0)), cmap='gray')\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {peak_signal_noise_ratio(out_np, clean_img_np):0.1f}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean inversion\n",
    "clean_recon_np = torch_to_np(net(net_input))\n",
    "clean_psnr = peak_signal_noise_ratio(out_np, clean_img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_grid([clean_img_np, clean_recon_np], 3, 11);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCT-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_dct import idct_2d\n",
    "\n",
    "method = 'DCT-Lasso'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "w = torch.randn_like(clean_img_torch)\n",
    "w.requires_grad = True\n",
    "criterion = torch.nn.L1Loss().type(dtype)\n",
    "optimizer = torch.optim.SGD([w], lr=1e6, momentum=0.99)\n",
    "lam = 1e-1\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = idct_2d(w)\n",
    "    loss = criterion(torch.matmul(out.reshape(1, -1), A.T), noisy_measurement_torch) + lam * torch.mean(torch.abs(w))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)), cmap='gray')\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = np.clip(torch_to_np(idct_2d(w)), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust-DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Robust-DIP'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "input_depth = 64\n",
    "\n",
    "net = skip(\n",
    "    input_depth,\n",
    "    num_output_channels=1,\n",
    "    num_channels_down = [8, 16, 32, 64, 128], \n",
    "    num_channels_up   = [8, 16, 32, 64, 128],\n",
    "    num_channels_skip = [0, 0, 0, 4, 4],\n",
    "    upsample_mode='bilinear',\n",
    "    need_sigmoid=True,\n",
    ").type(dtype)\n",
    "\n",
    "net_input = torch.randn(1, input_depth, imsize, imsize).type(dtype)\n",
    "criterion = torch.nn.L1Loss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(net_input)\n",
    "    loss = criterion(torch.matmul(out.reshape(1, -1), A.T), noisy_measurement_torch)\n",
    "    loss.backward()\n",
    "#     torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.02)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)), cmap='gray')\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = torch_to_np(net(net_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TV-DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'TV-DIP'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "input_depth = 64\n",
    "\n",
    "net = skip(\n",
    "    input_depth,\n",
    "    num_output_channels=1,\n",
    "    num_channels_down = [8, 16, 32, 64, 128], \n",
    "    num_channels_up   = [8, 16, 32, 64, 128],\n",
    "    num_channels_skip = [0, 0, 0, 4, 4],\n",
    "    upsample_mode='bilinear',\n",
    "    need_sigmoid=True,\n",
    ").type(dtype)\n",
    "\n",
    "net_input = torch.randn(1, input_depth, imsize, imsize).type(dtype)\n",
    "criterion = torch.nn.L1Loss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(net_input)\n",
    "    loss = criterion(torch.matmul(out.reshape(1, -1), A.T), noisy_measurement_torch) + 1e-4 * tv_loss(out)\n",
    "    loss.backward()\n",
    "#     torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.02)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)), cmap='gray')\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = torch_to_np(net(net_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS-DODIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 2\n",
    "method = 'CS-DODIP'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "net = skip(\n",
    "    input_depth, \n",
    "    clean_img_np.shape[0], \n",
    "    num_channels_down = [128] * 5,\n",
    "    num_channels_up   = [128] * 5,\n",
    "    num_channels_skip = [0] * 5,  \n",
    "    upsample_mode='nearest', \n",
    "    filter_skip_size=1, \n",
    "    filter_size_up=3, \n",
    "    filter_size_down=3,\n",
    "    need_sigmoid=True, \n",
    "    need_bias=True, \n",
    "    pad='reflection', \n",
    "    act_fun='LeakyReLU'\n",
    ").type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, 'meshgrid', clean_img_np.shape[1:]).type(dtype)\n",
    "criterion = torch.nn.MSELoss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "r_img_cor_p_torch = torch.zeros_like(noisy_measurement_torch).normal_()*1e-5\n",
    "r_img_cor_n_torch = torch.zeros_like(noisy_measurement_torch).normal_()*1e-5\n",
    "r_img_cor_p_torch.requires_grad = True\n",
    "r_img_cor_n_torch.requires_grad = True\n",
    "\n",
    "optimizer_sop = torch.optim.SGD([r_img_cor_p_torch, r_img_cor_n_torch], lr=100)\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_sop.zero_grad()\n",
    "    \n",
    "    out = net(net_input)\n",
    "    r_img_cor_torch = r_img_cor_p_torch ** 2 - r_img_cor_n_torch ** 2\n",
    "    loss = criterion(torch.matmul(out.reshape(1, -1), A.T) + r_img_cor_torch, noisy_measurement_torch)\n",
    "    loss.backward()\n",
    "#     torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.01)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer_sop.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)), cmap='gray')\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        plt.title(f'Noise Diff: {torch.sum(torch.abs(r_img_cor_torch - noise_torch)):0.3f}')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = torch_to_np(net(net_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in psnr_dict.items():\n",
    "    plt.plot(iteration_dict[k], v, '--', linewidth=3, label=k)\n",
    "plt.hlines(clean_psnr, 99, num_iterations, linestyles='dashdot', label='No Noise', linewidth=3, colors='black')\n",
    "plt.xlabel('Iteration', fontsize=15)\n",
    "plt.ylabel('PSNR', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend()\n",
    "plt.savefig('gs_psnr.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_image_grid([clean_recon_np, image_dict['DCT-Lasso'], image_dict['Robust-DIP'], image_dict['TV-DIP'], image_dict['CS-DODIP']])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title('[Clean, DCT-Lasso, Robust-DIP, TV-DIP, CS-DODIP]', fontsize=20)\n",
    "plt.savefig('gs_result_images.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "result_dict = {\n",
    "    'iteration': iteration_dict,\n",
    "    'image': image_dict,\n",
    "    'psnr': psnr_dict,\n",
    "    'clean_result': clean_recon_np,\n",
    "    'clean_psnr': clean_psnr\n",
    "}\n",
    "\n",
    "with open('gs_result.pl', 'wb') as handle:\n",
    "    pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_image_grid([clean_recon_np, image_dict['DCT-Lasso'], image_dict['Robust-DIP'], image_dict['TV-DIP'], image_dict['CS-DODIP']])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title('[Clean, DCT-Lasso, Robust-DIP, TV-DIP, CS-DODIP]', fontsize=20)\n",
    "plt.savefig('gs_result_images.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('gs_result.pl', 'rb') as handle:\n",
    "    result_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = result_dict['image']\n",
    "clean_recon_np = result_dict['clean_result']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPwLcw5URHcKe/7uE3FAora",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
