{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from models.skip import skip\n",
    "from models.downsampler import Downsampler\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.util import random_noise\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from utils.common_utils import get_image, crop_image, np_to_pil, pil_to_np, np_to_torch, torch_to_np, plot_image_grid, get_image_grid, get_noise\n",
    "from utils.sr_utils import load_LR_HR_imgs_sr, tv_loss\n",
    "\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "torch.manual_seed(0);\n",
    "np.random.seed(0)\n",
    "save_every = 250\n",
    "num_iterations = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/sr/zebra.png'\n",
    "\n",
    "imsize = -1\n",
    "dim_div_by = 64\n",
    "factor = 4\n",
    "\n",
    "downsampler = Downsampler(n_planes=3, factor=factor, kernel_type='lanczos2', phase=0.5, preserve_size=True).type(dtype)\n",
    "\n",
    "imgs = load_LR_HR_imgs_sr(img_path, imsize, factor, 'CROP')\n",
    "\n",
    "clean_hr_img_np = imgs['HR_np']\n",
    "clean_hr_img_torch = np_to_torch(clean_hr_img_np).type(dtype)\n",
    "clean_lr_img_np = np.clip(torch_to_np(downsampler(clean_hr_img_torch)), 0, 1)\n",
    "clean_lr_upscale_img_np = pil_to_np(np_to_pil(clean_lr_img_np).resize(imgs['HR_pil'].size))\n",
    " \n",
    "noisy_lr_img_np = random_noise(clean_lr_img_np, mode='s&p', amount=0.2)\n",
    "noisy_lr_upscale_img_np = pil_to_np(np_to_pil(noisy_lr_img_np).resize(imgs['HR_pil'].size))\n",
    "\n",
    "clean_lr_img_torch = np_to_torch(clean_lr_img_np).type(dtype)\n",
    "noisy_lr_img_torch = np_to_torch(noisy_lr_img_np).type(dtype)\n",
    "\n",
    "noise_diff_np = noisy_lr_img_np - clean_lr_img_np\n",
    "noise_diff_torch = np_to_torch(noise_diff_np).type(dtype)\n",
    "\n",
    "grid = get_image_grid([clean_hr_img_np, clean_lr_upscale_img_np, noisy_lr_upscale_img_np], 3);\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.savefig('sr_example.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for images and psnr\n",
    "image_dict = {}\n",
    "psnr_dict = {}\n",
    "iteration_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 2\n",
    "\n",
    "net = skip(\n",
    "    input_depth,\n",
    "    clean_hr_img_np.shape[0],\n",
    "    num_channels_down = [128] * 5,\n",
    "    num_channels_up   = [128] * 5,\n",
    "    num_channels_skip = [4] * 5, \n",
    "    upsample_mode='bilinear',\n",
    "    downsample_mode='stride',\n",
    "    need_sigmoid=True, \n",
    "    need_bias=True, \n",
    "    pad='reflection',\n",
    "    act_fun='LeakyReLU'\n",
    ").type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, 'noise', clean_hr_img_np.shape[1:]).type(dtype).detach()\n",
    "criterion = torch.nn.MSELoss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(net_input)\n",
    "    loss = criterion(downsampler(out), clean_lr_img_torch)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.02)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = torch_to_np(out)\n",
    "        \n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)))\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {peak_signal_noise_ratio(out_np, clean_hr_img_np):0.1f}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean SR\n",
    "clean_sr_np = torch_to_np(net(net_input))\n",
    "clean_psnr = peak_signal_noise_ratio(clean_sr_np, clean_hr_img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_grid([clean_hr_img_np, clean_lr_upscale_img_np, clean_sr_np], 3, 11);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCT-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_dct import idct_2d\n",
    "\n",
    "method = 'DCT-Lasso'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "w = torch.randn_like(clean_hr_img_torch)\n",
    "w.requires_grad = True\n",
    "criterion = torch.nn.L1Loss().type(dtype)\n",
    "optimizer = torch.optim.SGD([w], lr=5e7, momentum=0.99)\n",
    "lam = 5e-3\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = idct_2d(w)\n",
    "    loss = criterion(downsampler(out), noisy_lr_img_torch) + lam * torch.mean(torch.abs(w))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_hr_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)))\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = np.clip(torch_to_np(idct_2d(w)), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust-DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 2\n",
    "method = 'Robust-DIP'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "net = skip(\n",
    "    input_depth, \n",
    "    clean_hr_img_np.shape[0], \n",
    "    num_channels_down = [128] * 5,\n",
    "    num_channels_up   = [128] * 5,\n",
    "    num_channels_skip = [0] * 5,  \n",
    "    upsample_mode='nearest', \n",
    "    filter_skip_size=1, \n",
    "    filter_size_up=3, \n",
    "    filter_size_down=3,\n",
    "    need_sigmoid=True, \n",
    "    need_bias=True, \n",
    "    pad='reflection', \n",
    "    act_fun='LeakyReLU'\n",
    ").type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, 'meshgrid', clean_hr_img_np.shape[1:]).type(dtype)\n",
    "criterion = torch.nn.L1Loss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(net_input)\n",
    "    loss = criterion(downsampler(out), noisy_lr_img_torch)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.02)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = torch_to_np(out)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_hr_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)))\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = torch_to_np(net(net_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TV-DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 32\n",
    "method = 'TV-DIP'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "net = skip(\n",
    "    input_depth,\n",
    "    clean_hr_img_np.shape[0],\n",
    "    num_channels_down = [128] * 5,\n",
    "    num_channels_up   = [128] * 5,\n",
    "    num_channels_skip = [4] * 5, \n",
    "    upsample_mode='bilinear',\n",
    "    downsample_mode='stride',\n",
    "    need_sigmoid=True, \n",
    "    need_bias=True, \n",
    "    pad='reflection',\n",
    "    act_fun='LeakyReLU'\n",
    ").type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, 'noise', clean_hr_img_np.shape[1:]).type(dtype).detach()\n",
    "criterion = torch.nn.L1Loss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(net_input)\n",
    "    loss = criterion(downsampler(out), noisy_lr_img_torch) + 2e-6 * tv_loss(out)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.02)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_hr_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)))\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = torch_to_np(net(net_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS-DODIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 32\n",
    "method = 'CS-DODIP'\n",
    "\n",
    "psnr_dict[method] = []\n",
    "iteration_dict[method] = []\n",
    "\n",
    "net = skip(\n",
    "    input_depth,\n",
    "    clean_hr_img_np.shape[0],\n",
    "    num_channels_down = [128] * 5,\n",
    "    num_channels_up   = [128] * 5,\n",
    "    num_channels_skip = [4] * 5, \n",
    "    upsample_mode='bilinear',\n",
    "    downsample_mode='stride',\n",
    "    need_sigmoid=True, \n",
    "    need_bias=True, \n",
    "    pad='reflection',\n",
    "    act_fun='LeakyReLU'\n",
    ").type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, 'noise', clean_hr_img_np.shape[1:]).type(dtype).detach()\n",
    "criterion = torch.nn.MSELoss().type(dtype)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "r_img_cor_p_torch = torch.zeros_like(noisy_lr_img_torch).normal_()*1e-5\n",
    "r_img_cor_n_torch = torch.zeros_like(noisy_lr_img_torch).normal_()*1e-5\n",
    "r_img_cor_p_torch.requires_grad = True\n",
    "r_img_cor_n_torch.requires_grad = True\n",
    "\n",
    "optimizer_sop = torch.optim.SGD([r_img_cor_p_torch, r_img_cor_n_torch], lr=1000, momentum=0.99)\n",
    "\n",
    "for i in range(num_iterations+1):\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_sop.zero_grad()\n",
    "    \n",
    "    out = net(net_input)\n",
    "    r_img_cor_torch = r_img_cor_p_torch ** 2 - r_img_cor_n_torch ** 2\n",
    "    loss = criterion(downsampler(out) + r_img_cor_torch, noisy_lr_img_torch)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.01)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer_sop.step()\n",
    "    \n",
    "    if i % save_every == 0:\n",
    "        clear_output(wait=True)\n",
    "        out_np = np.clip(torch_to_np(out), 0, 1)\n",
    "        \n",
    "        iteration_dict[method].append(i)\n",
    "        psnr = peak_signal_noise_ratio(out_np, clean_hr_img_np)\n",
    "        psnr_dict[method].append(psnr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.clip(out_np, 0, 1).transpose((1, 2, 0)))\n",
    "        plt.title(f'Iteration: {i}/{num_iterations}, Loss: {loss.item():0.3e}, PSNR: {psnr:0.1f}')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.plot(iteration_dict[method], psnr_dict[method])\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('PSNR')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "image_dict[method] = torch_to_np(net(net_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in psnr_dict.items():\n",
    "    plt.plot(iteration_dict[k], v, '--', linewidth=3, label=k)\n",
    "plt.hlines(clean_psnr, 99, num_iterations, linestyles='dashdot', label='No Noise', linewidth=3, colors='black')\n",
    "plt.xlabel('Iteration', fontsize=15)\n",
    "plt.ylabel('PSNR', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend()\n",
    "plt.savefig('sr_psnr.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_image_grid([clean_sr_np, image_dict['DCT-Lasso'], image_dict['Robust-DIP'], image_dict['TV-DIP'], image_dict['CS-DODIP']])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title('[Clean, DCT-Lasso, Robust-DIP, TV-DIP, CS-DODIP]', fontsize=20)\n",
    "plt.savefig('sr_result_images.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "result_dict = {\n",
    "    'iteration': iteration_dict,\n",
    "    'image': image_dict,\n",
    "    'psnr': psnr_dict,\n",
    "    'clean_result': clean_sr_np,\n",
    "    'clean_psnr': clean_psnr\n",
    "}\n",
    "\n",
    "with open('sr_result.pl', 'wb') as handle:\n",
    "    pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = result_dict['image']\n",
    "clean_sr_np = result_dict['clean_result']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
